{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAvwt7SE5nhn"
   },
   "source": [
    "#Problem Statement: Bank Churn Prediction\n",
    "-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Objective:\n",
    "\n",
    "Given a Bank customer, build a neural network-based classifier that can determine whether they will leave or not.\n",
    "\n",
    "Context:\n",
    "\n",
    "Businesses like banks which provide service have to worry about the problem of 'Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a customer's decision in this regard. Management can concentrate efforts on improvement of service, keeping in mind these priorities.\n",
    "\n",
    "Data Description:\n",
    "\n",
    "The case study is from an open-source dataset from Kaggle. The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance etc. Link to the Kaggle project site: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    "\n",
    "Points Distribution:\n",
    "\n",
    "The points distribution for this case is as follows:\n",
    "\n",
    "Read the dataset\n",
    "Drop the columns which are unique for all users like IDs (5points)\n",
    "Distinguish the features and target variable(5points)\n",
    "Divide the data set into training and test sets (5points)\n",
    "Normalize the train and test data (10points)\n",
    "Initialize & build the model. Identify the points of improvement and implement the same. Note that you need to demonstrate at least two models(the original and the improved one) and highlight the differences to complete this point. You can also demonstrate more models. (20points)\n",
    "Predict the results using 0.5 as a threshold. Note that you need to first predict the probability and then predict classes using the given threshold (10points)\n",
    "Print the Accuracy score and confusion matrix (5points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "AmqvA4F-8QSc",
    "outputId": "30dfaff0-7880-48e3-fb88-bebb7f40ea11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.32.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.18.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (3.12.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.35.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (50.3.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.17.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uv-aVHzf8v2K",
    "outputId": "e3b1cf56-92ca-4042-bc33-b8099cc17339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "tZW7vYO083C8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "zjQK8dMS850u"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TbxY1wNC9AKA",
    "outputId": "9cfd521b-8702-422c-9606-aa8fe566dfbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "Awe244WF9MnZ"
   },
   "outputs": [],
   "source": [
    "project_path = '/content/drive/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "SJVZdbol9caa"
   },
   "outputs": [],
   "source": [
    "dataset_file = project_path + 'bank.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "RrKUSvmB9hSE"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "H-Atl9bF9kC_",
    "outputId": "299f892d-25aa-4c80-ceb9-a042f688783b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSocN-el6Gsv"
   },
   "source": [
    "# From reviewing the data, customerid, surname are unique and wont contribute towards data analysis and will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "hmIYDJxsCDFC"
   },
   "outputs": [],
   "source": [
    "data=data.drop(\"CustomerId\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "KTt3M7MHGci0"
   },
   "outputs": [],
   "source": [
    "data=data.drop(\"Surname\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "8zCt127ACKFa",
    "outputId": "e1bf65af-69ef-4e44-c65f-a0c31be90662"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>616</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>549</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>587</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CreditScore Geography  ... IsActiveMember  EstimatedSalary  Exited\n",
       "0           1          619    France  ...              1        101348.88       1\n",
       "1           2          608     Spain  ...              1        112542.58       0\n",
       "2           3          502    France  ...              0        113931.57       1\n",
       "3           4          699    France  ...              0         93826.63       0\n",
       "4           5          850     Spain  ...              1         79084.10       0\n",
       "5           6          645     Spain  ...              0        149756.71       1\n",
       "6           7          822    France  ...              1         10062.80       0\n",
       "7           8          376   Germany  ...              0        119346.88       1\n",
       "8           9          501    France  ...              1         74940.50       0\n",
       "9          10          684    France  ...              1         71725.73       0\n",
       "10         11          528    France  ...              0         80181.12       0\n",
       "11         12          497     Spain  ...              0         76390.01       0\n",
       "12         13          476    France  ...              0         26260.98       0\n",
       "13         14          549    France  ...              0        190857.79       0\n",
       "14         15          635     Spain  ...              1         65951.65       0\n",
       "15         16          616   Germany  ...              1         64327.26       0\n",
       "16         17          653   Germany  ...              0          5097.67       1\n",
       "17         18          549     Spain  ...              1         14406.41       0\n",
       "18         19          587     Spain  ...              0        158684.81       0\n",
       "19         20          726    France  ...              1         54724.03       0\n",
       "\n",
       "[20 rows x 12 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E8KqXyvBGRv"
   },
   "source": [
    "Distinguish the features and target variables\n",
    "The bank customer are from three countries - France, Spain and germany with a good mix of male and female customers. THe exited column is the target column which indicates whether customer has left the bank or not.. the churn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "B3urGC3MB3qI",
    "outputId": "253ac0ee-7cc1-4ff3-888e-2bab2e713967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb17a1d8cf8>"
      ]
     },
     "execution_count": 265,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " import seaborn as sns\n",
    " sns.countplot(x=\"Exited\", hue=\"Gender\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9PbuFNOCaXG"
   },
   "source": [
    "The plot indicates that more men are existing customers vs females and females have a slightly higher propensity to exit the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "EwNZ7RzoCoui",
    "outputId": "817fb371-afa4-430b-ec9f-92431894901e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb17a19ef28>"
      ]
     },
     "execution_count": 266,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Exited\", hue=\"Geography\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jp6zttmCsUW"
   },
   "source": [
    "France has more customers than spain and germany. France and germany customers have more exits than spain. Based on the analysis, the target column is exit which can be used to predict the churn rate and feature columns form the rest of the data set including credit score, gender, geogrpahy, salary and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "QTnblgvlJMMH"
   },
   "outputs": [],
   "source": [
    "#Split the data into features and targets\n",
    "x = data.iloc[:, 0:10]\n",
    "y = data.iloc[:,11]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "JYpVRvA49KHt",
    "outputId": "970a6ad7-09f8-480e-e661-f4ca5e864b79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CreditScore  Age  ...  Geography_Spain  Gender_Female  Gender_Male\n",
       "0             1          619   42  ...                0              1            0\n",
       "1             2          608   41  ...                1              1            0\n",
       "2             3          502   42  ...                0              1            0\n",
       "3             4          699   39  ...                0              1            0\n",
       "4             5          850   43  ...                1              1            0\n",
       "...         ...          ...  ...  ...              ...            ...          ...\n",
       "9995       9996          771   39  ...                0              0            1\n",
       "9996       9997          516   35  ...                0              0            1\n",
       "9997       9998          709   36  ...                0              1            0\n",
       "9998       9999          772   42  ...                0              0            1\n",
       "9999      10000          792   28  ...                0              1            0\n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dummy variables for the categorical features (Geography and Gender)\n",
    "x = pd.get_dummies(x)\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "ROIHiheQeBcn"
   },
   "outputs": [],
   "source": [
    "#dropping one of the geography columns as data can be inferred from the other two columns\n",
    "x=x.drop(\"Geography_Spain\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "opI81N9teYWF"
   },
   "outputs": [],
   "source": [
    "# dropping one of the gender columns as data can be inferred from the other column\n",
    "x=x.drop(\"Gender_Male\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "mpyRMqVeeN2t",
    "outputId": "fde884fb-9a26-4dbb-9dee-5e8dad4a25d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Gender_Female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CreditScore  ...  Geography_Germany  Gender_Female\n",
       "0             1          619  ...                  0              1\n",
       "1             2          608  ...                  0              1\n",
       "2             3          502  ...                  0              1\n",
       "3             4          699  ...                  0              1\n",
       "4             5          850  ...                  0              1\n",
       "...         ...          ...  ...                ...            ...\n",
       "9995       9996          771  ...                  0              0\n",
       "9996       9997          516  ...                  0              0\n",
       "9997       9998          709  ...                  0              1\n",
       "9998       9999          772  ...                  1              0\n",
       "9999      10000          792  ...                  0              1\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zWUus-K1JjVx",
    "outputId": "b9e23454-6fa2-429d-9909-44bcb4ac533e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 11) (3000, 11) (7000,) (3000,)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "gqKge8-AJraj"
   },
   "outputs": [],
   "source": [
    "# Normalize / Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "GbMA3Q9xJzdN"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tiYKEAL7jBQ"
   },
   "source": [
    "First ANN Model with 1 Hidden layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "9Fn8PPxyzD-p"
   },
   "outputs": [],
   "source": [
    "#Initialise Model\n",
    "Model1=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "bIb8yPgQzFmh"
   },
   "outputs": [],
   "source": [
    "#ADD input layer and 1st hidden layer\n",
    "Model1.add(Dense(input_dim=11, units=5,activation=\"sigmoid\",kernel_initializer=\"uniform\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "iN1n1yXGzNtm"
   },
   "outputs": [],
   "source": [
    "#added the output layer\n",
    "Model1.add(Dense(units=1,activation=\"sigmoid\",kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "id": "hKDK1wUBzREM"
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "Model1.compile(optimizer=\"sgd\",loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KDyQ5zrqzUx2",
    "outputId": "9b9ba1ef-4240-4106-90ad-08f780f60cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "700/700 [==============================] - 1s 873us/step - loss: 0.5310\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 1s 874us/step - loss: 0.4978\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 1s 828us/step - loss: 0.4917\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 1s 824us/step - loss: 0.4853\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 1s 835us/step - loss: 0.4784\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 1s 814us/step - loss: 0.4712\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 1s 834us/step - loss: 0.4643\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 1s 852us/step - loss: 0.4576\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 1s 845us/step - loss: 0.4517\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 1s 842us/step - loss: 0.4465\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 1s 828us/step - loss: 0.4422\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 1s 829us/step - loss: 0.4386\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 1s 833us/step - loss: 0.4358\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 1s 836us/step - loss: 0.4335\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 1s 850us/step - loss: 0.4317\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 1s 970us/step - loss: 0.4305\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 1s 934us/step - loss: 0.4295\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 1s 934us/step - loss: 0.4287\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 1s 954us/step - loss: 0.4282\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 1s 952us/step - loss: 0.4278\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 1s 951us/step - loss: 0.4274\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 1s 973us/step - loss: 0.4272\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 1s 979us/step - loss: 0.4270\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 1s 959us/step - loss: 0.4269\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 1s 935us/step - loss: 0.4268\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 1s 935us/step - loss: 0.4267\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 1s 950us/step - loss: 0.4267\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 1s 994us/step - loss: 0.4266\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 1s 956us/step - loss: 0.4266\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 1s 959us/step - loss: 0.4265\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 1s 892us/step - loss: 0.4265\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 1s 821us/step - loss: 0.4265\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 1s 828us/step - loss: 0.4264\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 1s 807us/step - loss: 0.4264\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 1s 812us/step - loss: 0.4264\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 1s 820us/step - loss: 0.4264\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 1s 815us/step - loss: 0.4264\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 1s 811us/step - loss: 0.4263\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 1s 827us/step - loss: 0.4263\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 1s 801us/step - loss: 0.4262\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 1s 842us/step - loss: 0.4262\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 1s 808us/step - loss: 0.4261\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 1s 817us/step - loss: 0.4261\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 1s 804us/step - loss: 0.4260\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 1s 789us/step - loss: 0.4260\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 1s 781us/step - loss: 0.4260\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 1s 802us/step - loss: 0.4259\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 1s 851us/step - loss: 0.4258\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 1s 836us/step - loss: 0.4257\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 1s 853us/step - loss: 0.4256\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 1s 836us/step - loss: 0.4255\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 1s 824us/step - loss: 0.4254\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 1s 841us/step - loss: 0.4253\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 1s 838us/step - loss: 0.4252\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 1s 839us/step - loss: 0.4250\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 1s 858us/step - loss: 0.4249\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 1s 808us/step - loss: 0.4246\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 1s 833us/step - loss: 0.4245\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 1s 850us/step - loss: 0.4244\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 1s 847us/step - loss: 0.4242\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 1s 832us/step - loss: 0.4240\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 1s 831us/step - loss: 0.4237\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 1s 832us/step - loss: 0.4234\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 1s 825us/step - loss: 0.4232\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 1s 842us/step - loss: 0.4229\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 1s 830us/step - loss: 0.4226\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 1s 841us/step - loss: 0.4223\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 1s 844us/step - loss: 0.4220\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 1s 853us/step - loss: 0.4215\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 1s 821us/step - loss: 0.4214\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 1s 868us/step - loss: 0.4210\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 1s 852us/step - loss: 0.4207\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 1s 829us/step - loss: 0.4203\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 1s 858us/step - loss: 0.4199\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 1s 848us/step - loss: 0.4196\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 1s 836us/step - loss: 0.4192\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 1s 831us/step - loss: 0.4188\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 1s 845us/step - loss: 0.4185\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 1s 850us/step - loss: 0.4181\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 1s 833us/step - loss: 0.4177\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 1s 854us/step - loss: 0.4173\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 1s 845us/step - loss: 0.4170\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 1s 834us/step - loss: 0.4167\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 1s 840us/step - loss: 0.4163\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 1s 841us/step - loss: 0.4159\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 1s 827us/step - loss: 0.4156\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 1s 842us/step - loss: 0.4153\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 1s 836us/step - loss: 0.4149\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 1s 845us/step - loss: 0.4146\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 1s 821us/step - loss: 0.4143\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 1s 852us/step - loss: 0.4139\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 1s 880us/step - loss: 0.4135\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 1s 871us/step - loss: 0.4133\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 1s 827us/step - loss: 0.4130\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 1s 855us/step - loss: 0.4127\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 1s 844us/step - loss: 0.4125\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 1s 830us/step - loss: 0.4122\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 1s 864us/step - loss: 0.4119\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 1s 882us/step - loss: 0.4117\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 1s 856us/step - loss: 0.4114\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Model to the Training set\n",
    "var1 = Model1.fit(x_train, y_train, batch_size = 10, epochs = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "azBvZa-fcatT",
    "outputId": "a3dc2081-63ac-4c5d-8653-fa42135cf53f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21331087],\n",
       "       [0.34628648],\n",
       "       [0.18801102],\n",
       "       [0.07703832],\n",
       "       [0.15757227],\n",
       "       [0.63785994],\n",
       "       [0.04276767],\n",
       "       [0.04532385],\n",
       "       [0.3262357 ],\n",
       "       [0.6781127 ],\n",
       "       [0.09488094],\n",
       "       [0.14112806],\n",
       "       [0.2941992 ],\n",
       "       [0.14115891],\n",
       "       [0.49219483],\n",
       "       [0.43076077],\n",
       "       [0.29623586],\n",
       "       [0.30479258],\n",
       "       [0.05320573],\n",
       "       [0.17483583],\n",
       "       [0.4080093 ],\n",
       "       [0.03673723],\n",
       "       [0.14020735],\n",
       "       [0.13666213],\n",
       "       [0.03607062]], dtype=float32)"
      ]
     },
     "execution_count": 280,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Model1.predict(x_test)[:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "YEZ0SRGmc8-s",
    "outputId": "ed79107f-25fa-4ec3-aacd-173e77ac880b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 281,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_Model1 = Model1.predict(x_test)\n",
    "y_pred_Model1a = (y_pred > 0.5)\n",
    "y_pred_Model1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "_Wu-lR0NgTYk",
    "outputId": "d3b8b2f9-4cb5-4351-d21f-42acf831cfc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Model Test Resuls with 0.5 Threshold \n",
      "\n",
      "           First ANN Model\n",
      "accuracy          0.840333\n",
      "recall            0.338164\n",
      "precision         0.755396\n",
      "f1_score          0.467186\n"
     ]
    }
   ],
   "source": [
    "print('First Model Test Resuls with 0.5 Threshold \\n')\n",
    "Test_Results_First_Model=pd.DataFrame(data=[accuracy_score(y_test, y_pred_Model1a), \n",
    "                   recall_score(y_test, y_pred_Model1a), \n",
    "                   precision_score(y_test, y_pred_Model1a),\n",
    "                   f1_score(y_test, y_pred_Model1a)], columns=['First ANN Model'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Results_First_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5hFH5Rt9on7"
   },
   "source": [
    "In the First Model Accuracy is high, recal is low, precision is high and F1 score is lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "xyudNValzfKv",
    "outputId": "84fc64f7-9237-4cf3-bee6-f8ae056ed539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2311  411]\n",
      " [  68  210]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "conf_Model1=confusion_matrix(y_pred_Model1a,y_test)\n",
    "print(conf_Model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zK0aNQIG4jMi",
    "outputId": "2aef19d4-c1d9-49b7-bb0a-c5934b692e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.7767\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s 975us/step - loss: 0.4939 - accuracy: 0.7977\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7977\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7977\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7977\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s 953us/step - loss: 0.4379 - accuracy: 0.7977\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7977\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7977\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.7977\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s 977us/step - loss: 0.4222 - accuracy: 0.7979\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s 987us/step - loss: 0.4196 - accuracy: 0.8023\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8104\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8136\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8123\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8103\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s 997us/step - loss: 0.4089 - accuracy: 0.8130\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8187\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8263\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s 971us/step - loss: 0.3962 - accuracy: 0.8300\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8414\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s 986us/step - loss: 0.3762 - accuracy: 0.8441\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s 984us/step - loss: 0.3701 - accuracy: 0.8481\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s 983us/step - loss: 0.3655 - accuracy: 0.8521\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8527\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8523\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s 958us/step - loss: 0.3560 - accuracy: 0.8540\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8559\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8554\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8563\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8554\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s 955us/step - loss: 0.3486 - accuracy: 0.8579\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8574\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s 996us/step - loss: 0.3462 - accuracy: 0.8597\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8590\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s 964us/step - loss: 0.3452 - accuracy: 0.8597\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8594\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s 968us/step - loss: 0.3443 - accuracy: 0.8587\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8606\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8606\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8613\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8604\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8604\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8610\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s 992us/step - loss: 0.3415 - accuracy: 0.8613\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s 989us/step - loss: 0.3413 - accuracy: 0.8629\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8621\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s 984us/step - loss: 0.3406 - accuracy: 0.8620\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8626\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s 961us/step - loss: 0.3400 - accuracy: 0.8619\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8630\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8623\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8633\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8623\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8627\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8621\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8634\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s 989us/step - loss: 0.3384 - accuracy: 0.8627\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8617\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8623\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8637\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8630\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8637\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8631\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8634\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8633\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8640\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8636\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8636\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8631\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8636\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8631\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8644\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8651\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8644\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8650\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8643\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8646\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8651\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8643\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8646\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8641\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8654\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8649\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8651\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8647\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8649\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8644\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8651\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8659\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8650\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8650\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8657\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8640\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8653\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8647\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8646\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "# Second ANN Model with Activation Function:relu and second hidden layer\n",
    "Model2=Sequential()\n",
    "Model2.add(Dense(input_dim=11, units=6,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "Model2.add(Dense(units=5,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "Model2.add(Dense(units=1,activation=\"sigmoid\",kernel_initializer=\"uniform\"))\n",
    "Model2.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "\n",
    "Model2_ANN=Model2.fit(x_train,y_train,batch_size=50,epochs=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "YWR7bWV_q08k",
    "outputId": "fe654739-8661-4f5a-9aa2-fa6d1ee128e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2974329 ],\n",
       "       [0.27111113],\n",
       "       [0.14610344],\n",
       "       [0.06800026],\n",
       "       [0.0394339 ],\n",
       "       [0.9374454 ],\n",
       "       [0.02525094],\n",
       "       [0.10437009],\n",
       "       [0.22065836],\n",
       "       [0.89079154],\n",
       "       [0.02399433],\n",
       "       [0.2869738 ],\n",
       "       [0.37680602],\n",
       "       [0.28067482],\n",
       "       [0.5609281 ],\n",
       "       [0.41605523],\n",
       "       [0.10437056],\n",
       "       [0.15755647],\n",
       "       [0.11201096],\n",
       "       [0.09790084],\n",
       "       [0.5350207 ],\n",
       "       [0.00342909],\n",
       "       [0.05984315],\n",
       "       [0.07353589],\n",
       "       [0.00305769]], dtype=float32)"
      ]
     },
     "execution_count": 285,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Model2.predict(x_test)[:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "zohPduM-oea1",
    "outputId": "c40468c1-a485-498e-9c07-aa66a10b2fef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 286,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_Model2=Model2.predict(x_test)\n",
    "y_pred_Model2a=(y_pred_Model2>0.5)\n",
    "y_pred_Model2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "3iXL0ESgoQSm",
    "outputId": "6a861180-789b-4a7b-b449-6827666c171f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Model Test Resuls with 0.5 Threshold \n",
      "\n",
      "           Second ANN Model\n",
      "accuracy           0.860000\n",
      "recall             0.495974\n",
      "precision          0.742169\n",
      "f1_score           0.594595\n"
     ]
    }
   ],
   "source": [
    "print('Second Model Test Resuls with 0.5 Threshold \\n')\n",
    "Test_Results_Second_Model=pd.DataFrame(data=[accuracy_score(y_test, y_pred_Model2a), \n",
    "                   recall_score(y_test, y_pred_Model2a), \n",
    "                   precision_score(y_test, y_pred_Model2a),\n",
    "                   f1_score(y_test, y_pred_Model2a)], columns=['Second ANN Model'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Results_Second_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GZmfN9z92jW"
   },
   "source": [
    "In the second model, accuracy is slightly higher, recall is better, precisio is similar and F1 score is higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "qeQ7z9o3ojjJ",
    "outputId": "24cd51a8-7d05-43fb-fed7-18958def4113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2272  313]\n",
      " [ 107  308]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "conf_Model2=confusion_matrix(y_pred_Model2a,y_test)\n",
    "print(conf_Model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "J6541OeH5UrL"
   },
   "outputs": [],
   "source": [
    "# Third ANN model using forward and backward propogation\n",
    "Model3 = Sequential()\n",
    "Model3.add(Dense(64, input_shape = (11,), activation = 'relu'))\n",
    "Model3.add(Dense(32, activation = 'tanh'))\n",
    "Model3.add(Dense(1, activation = 'sigmoid'))\n",
    "sgd = optimizers.Adam(lr = 0.001)\n",
    "Model3.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5CBjtsPIsHp9",
    "outputId": "8b480469-5cb2-44a1-f88c-36daddd19730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6916\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7976\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7977\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7983\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8024\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8071\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.8091\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8111\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8133\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8171\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8203\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8210\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8246\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8263\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8296\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8356\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8394\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8421\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8437\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8461\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8500\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8524\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8559\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8557\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8586\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8591\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8613\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8624\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8634\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8627\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8650\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8629\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8651\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8653\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8639\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8641\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8643\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8657\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8661\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8660\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8653\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8669\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8669\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8676\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8671\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8679\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8677\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8687\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8681\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8687\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8683\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8697\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8690\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8680\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8687\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8701\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8704\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8680\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8699\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8711\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8693\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8710\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8706\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8711\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8706\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8720\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8723\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8697\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8734\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8690\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8727\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8706\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8737\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8740\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8726\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8743\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8703\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8746\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8746\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8743\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8727\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8720\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8740\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8720\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8743\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8727\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8743\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8743\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8743\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8729\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8744\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8729\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8743\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8741\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8753\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8731\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb17de86ac8>"
      ]
     },
     "execution_count": 290,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model3.fit(x_train, y_train.values, batch_size = 700, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "jSd_eTdG6BaJ",
    "outputId": "9fa6be13-f86e-4b21-eca6-37a26e3b40d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26294   ],\n",
       "       [0.26057434],\n",
       "       [0.09544542],\n",
       "       [0.03820667],\n",
       "       [0.08644459],\n",
       "       [0.91543883],\n",
       "       [0.01510513],\n",
       "       [0.19238517],\n",
       "       [0.2825992 ],\n",
       "       [0.94690555],\n",
       "       [0.02096248],\n",
       "       [0.16183102],\n",
       "       [0.38083673],\n",
       "       [0.2682932 ],\n",
       "       [0.7350957 ],\n",
       "       [0.40754792],\n",
       "       [0.07787648],\n",
       "       [0.10551438],\n",
       "       [0.06428808],\n",
       "       [0.06274158],\n",
       "       [0.514379  ],\n",
       "       [0.00453585],\n",
       "       [0.0181509 ],\n",
       "       [0.10116041],\n",
       "       [0.00368193]], dtype=float32)"
      ]
     },
     "execution_count": 291,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Model3.predict(x_test)[:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "Tn_0Ne-s6JuU",
    "outputId": "a88e5d5c-5868-42f9-c2e3-f60f95779767"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 292,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_Model3=Model3.predict(x_test)\n",
    "y_pred_Model3a=(y_pred_Model3>0.5)\n",
    "y_pred_Model3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "F3L9T3qi6OAp",
    "outputId": "e162013a-664c-4829-fd41-a5b3370f6f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third Model Test Resuls with 0.5 Threshold \n",
      "\n",
      "           Third ANN Model\n",
      "accuracy          0.861333\n",
      "recall            0.491143\n",
      "precision         0.753086\n",
      "f1_score          0.594542\n"
     ]
    }
   ],
   "source": [
    "print('Third Model Test Resuls with 0.5 Threshold \\n')\n",
    "Test_Results_Third_Model=pd.DataFrame(data=[accuracy_score(y_test, y_pred_Model3a), \n",
    "                   recall_score(y_test, y_pred_Model3a), \n",
    "                   precision_score(y_test, y_pred_Model3a),\n",
    "                   f1_score(y_test, y_pred_Model3a)], columns=['Third ANN Model'],\n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\n",
    "print(Test_Results_Third_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_Jiaqr-CCX"
   },
   "source": [
    "In third model, all parameters are better than the previous 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "SdZ4gjuJuD6x",
    "outputId": "77f41a86-aa50-4e45-89b2-44f39e7017de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First ANN Model</th>\n",
       "      <th>Second Model</th>\n",
       "      <th>Third Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.840333</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.861333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.338164</td>\n",
       "      <td>0.495974</td>\n",
       "      <td>0.491143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.755396</td>\n",
       "      <td>0.742169</td>\n",
       "      <td>0.753086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.467186</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.594542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           First ANN Model  Second Model  Third Model\n",
       "accuracy          0.840333      0.860000     0.861333\n",
       "recall            0.338164      0.495974     0.491143\n",
       "precision         0.755396      0.742169     0.753086\n",
       "f1_score          0.467186      0.594595     0.594542"
      ]
     },
     "execution_count": 294,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_Results_Comparison=Test_Results_First_Model\n",
    "ANN_Results_Comparison['Second Model']=Test_Results_Second_Model\n",
    "ANN_Results_Comparison['Third Model']=Test_Results_Third_Model\n",
    "ANN_Results_Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOEqIg6V-HBC"
   },
   "source": [
    "The third ANN model is better than the first two models across all parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYie4x4l-dn4"
   },
   "source": [
    "Confusion Matrix for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "9su-TvPU-VbU",
    "outputId": "aa4b385c-c299-43dc-faf6-5e7db037e294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2311  411]\n",
      " [  68  210]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "conf_Model1=confusion_matrix(y_pred_Model1a,y_test)\n",
    "print(conf_Model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "osFndL57-h-W",
    "outputId": "ae420940-3252-4d87-cbc7-6eb13381144c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2272  313]\n",
      " [ 107  308]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "conf_Model2=confusion_matrix(y_pred_Model2a,y_test)\n",
    "print(conf_Model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "GGNJgoRy-mbR",
    "outputId": "5fe8fa64-df17-4b66-ad88-dcd7bc15d48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2279  316]\n",
      " [ 100  305]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "conf_Model3=confusion_matrix(y_pred_Model3a,y_test)\n",
    "print(conf_Model3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bank Churn Rate ANN - Balaji Ariyanan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
